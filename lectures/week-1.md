# Section 1 Notes

## Problem Solving Process

1. Identify data that is relevant to the problem.
2. Assemble a set of data related to the problem you're trying to fix.
3. Decide on the type of output you are predicting.
4. Based on the type of out,pick an algorithm that will determine a correlation between your 'features' and 'labels'.
5. Use model generated by algorithm to make a prediction.

Decided on the type of output.
Classification -> The value of our labels belongs to a discrete set. The value of our labels belong to a discrete set.

Regression -> The value of our labels belong to a continuous set. We are trying to predict the value of our sets. The value of our labels belong to a continuous set.

## Problem Solving Process:

![Problem Solving Process](img/week-1/week-1-problem-solve-process.png "Problem Solving Process")

1. Identify the data:
Game Breakdown
![Game Breakdown](img/week-1/week-1-game-breakdown.png
 "Game Breakdown")
 Using an array to capture the data.
 ![Array of Arrays](img/week-1/04-array-of-arrarys-used.png)
 Since the ball land in a designated buckets(labels/categories) the type of output selected will be classification.[steps 1 to 3]

4. Based on the data the algorithm selected was K-Nearest Neighbor(knn) Idiom that relates to knn is birds of a feather flock together

## K-Nearest Neighbor (KNN)

![K-Nearest Neighbor](img/week-1/05-knn-problem.png "K-Nearest Neighbor")

After building the first algorithm you may not see the results you want.
![Bad Predictions](img/week-1/06-bad-predictions.png "Bad Predictions")

## Multi Dimensional KNN Algorithm

Using the Pythagorean theorem to calculate the distance between each ball.
Two feature distance calculation (bounciness and drop location). Adding the ball size will make this a three feature calculation.

![Pythagorean theorem](img/week-1/07-distance-ball.png)
![3D Pythagorean theorem](img/week-1/08-3d-pt.png)

End of fundamental of introduction.
![End of intro](img/week-1/09-end-of-intro.png)

## Pros and Cons of Lodash

![Pros and cons of lodash](img/week-1/10-pros-cons-lodash.png)

## Pros and Cons of Tensorflow JS

Methods are very similar to Lodash making the transition from Lodash very easy.
![Tensorflow JS](img/week-1/11-tensorflow-pro-con.png)

## Tensorflow

You can find Tensorflow docs at: [Docs](https://js.tensorflow.org)

## Tensor dimensions

Dimensions in an array.
![Tensor dimensions](img/week-1/12-dim.png)

3D Tensor dimensions.
![3D Tensor](img/week-1/13-3d-dims.png)

## Shape property

Row - Columns
![row columns](img/week-1/14-2d-shapes.png)

## Linear Regression (different paradigm than knn)

The goal of linear progression is to find an independent variables we can relay to a dependent variable. One great benefit of using Tensor is having one or more independent variables to one dependant variable. This is a major benefit than spreadsheet linear tables which only allow the use of one independent variable to one dependant variable.
![Pros and cons of Linear Regression](img/week-1/15-linear-regression.png)

  

## Mean Squared Error

Using the two mean squared error we can calculate how wrong were we from the actual data points. 

![Mean Squared Error](img/week-1/16-mean-sq-error.png)
**The lower the mean squared error the close it is to the actual data point. MSE is unlikely to ever be exactly 0.** For example in the chart below even the close guesses they still have a gap from the equation line.

![MSE Zero](img/week-1/17-mse-zero.png)


![ ](img/week-1/17-mse-eq.png)